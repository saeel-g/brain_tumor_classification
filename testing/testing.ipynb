{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, multilabel_confusion_matrix, roc_curve, confusion_matrix, accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow import keras\n",
    "import glob\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.models.load_model('../trained models/train_Densenet121.h5')\n",
    "\n",
    "\n",
    "SIZE=256\n",
    "test = pd.read_csv('../testing/test_dataset/test_labels.csv')\n",
    "\n",
    "import pandas as pd\n",
    "df_test = pd.DataFrame(test)\n",
    "test_labels=df_test['IMG'].values\n",
    "\n",
    "\n",
    "\n",
    "test_image = []\n",
    "for i in tqdm(test_labels):\n",
    "    img = image.load_img(f'../testing/test_dataset/{str(i)}', target_size=(SIZE, SIZE,3))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img[:, :, 0]  # Take only one channel (assuming it's a grayscale image)\n",
    "    img = img / 255\n",
    "    img = np.expand_dims(img, axis=-1)  # Add a singleton dimension for the channel\n",
    "    test_image.append(img)\n",
    "\n",
    "\n",
    "X_test = np.array(test_image)\n",
    "y_test = np.array(test.drop(['IMG'],axis=1))\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 8  # Set your desired batch size\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(batch_size)\n",
    "_, acc = model.evaluate(test_dataset)\n",
    "\n",
    "\n",
    "print(\"Accuracy = \", (acc * 100.0), \"%\")\n",
    "\n",
    "\n",
    "y_pred1 = model.predict(X_test)\n",
    "\n",
    "roc=roc_auc_score(y_test, y_pred1, multi_class='ovr', average='micro')\n",
    "print(\"AUC= \",roc)\n",
    "\n",
    "\n",
    "\n",
    "df_test=y_test\n",
    "y_test_df=df_test.argmax(axis=1)\n",
    "\n",
    "df_pred=y_pred1\n",
    "y_pred_df=df_pred.argmax(axis=1)\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test_df, y_pred_df)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Choose a specific class as the positive class (adjust class_index accordingly)\n",
    "true_positive=[]\n",
    "true_negative=[]\n",
    "false_positive=[]\n",
    "false_negative=[]\n",
    "for i in range(4):\n",
    "    positive_class_index = i\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_df == positive_class_index, y_pred_df == positive_class_index).ravel()\n",
    "    print(\"True Positive:\", tp, \"False Positive:\", fp, \"True Negative:\", tn, \"False Negative:\", fn)\n",
    "    print('*****'*5)\n",
    "\n",
    "    true_positive.append(tp)\n",
    "    true_negative.append(tn)\n",
    "    false_positive.append(fp)\n",
    "    false_negative.append(fn)\n",
    "\n",
    "print(true_positive)\n",
    "print(true_negative)\n",
    "print(false_positive)\n",
    "print(false_negative)\n",
    "\n",
    "total_tp=np.sum(true_positive)\n",
    "total_tn=np.sum(true_negative)\n",
    "total_fp=np.sum(false_positive)\n",
    "total_fn=np.sum(false_negative)\n",
    "\n",
    "print(total_tp)\n",
    "print(total_tn)\n",
    "print(total_fp)\n",
    "print(total_fn)\n",
    "\n",
    "\n",
    "# Calculate Precision, Recall, F1-Score, and Accuracy for the entire model\n",
    "total_PR = total_tp / (total_tp + total_fp)\n",
    "total_RC = total_tp / (total_tp + total_fn)\n",
    "total_F1 = 2 * (total_PR * total_RC) / (total_PR + total_RC)\n",
    "total_ACC = (total_tp + total_tn) / (total_tp + total_fp + total_tn + total_fn)\n",
    "\n",
    "print(\"\\nMetrics for the Entire Model:\")\n",
    "print(\"Total True Positive:\", total_tp)\n",
    "print(\"Total True Negative:\", total_tn)\n",
    "print(\"Total False Positive:\", total_fp)\n",
    "print(\"Total False Negative:\", total_fn)\n",
    "print(\"\\nPrecision: \", total_PR, \"\\nRecall: \", total_RC, \"\\nF1-Score\", total_F1, \"\\nAccuracy:\", total_ACC, \"\\nAUC\", roc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
